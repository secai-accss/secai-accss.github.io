# 2nd ACCSS Security & AI Workshop: Security and Privacy in the Age of Generative AI

Organised by the <a href="https://secai-accss.github.io" target="_blank" rel="noopener">ACCSS Working Group on AI & Security</a>, this event brings together researchers at the intersection of security/privacy and artificial intelligence to foster innovation and share cutting-edge ideas, experiences, and research opportunities.

A key feature of this year’s edition will be breakout sessions on topics collected from the community, enabling focused discussions and collaborative exchange on emerging challenges. Participants are also invited to submit posters to present their work and engage with peers in an open and interactive setting.

When registering, you will have the opportunity to suggest topics for the breakout sessions, helping shape the conversation.

## Details
- Date: 23 October 2025 10:00-16:00 
- Location: TU Delft - Mekelweg 5, 2628 CD Delft
- Register before <strong>15th October</strong>: [https://forms.microsoft.com/e/5niriCUZ7V](https://forms.microsoft.com/e/5niriCUZ7V)
- [Check here the program](#programme)


<h2>Keynote Speakers</h2>

<div class="speaker">
  <img src="{{ '/assets/img/maggie.jpg' | relative_url }}" alt="Dr. Mengyuan (Maggie) Zhang headshot" loading="lazy">
  <div class="speaker-body">
    <h3>Dr. Mengyuan (Maggie) Zhang <span>— Vrije Universiteit Amsterdam</span></h3>
    <p><strong>Talk Title:</strong> <em>Quantifiable Security: Challenges and Opportunities in the Age of AI</em>
    </p>
     <p><strong>Abstract:</strong> Quantifying security has always been at the heart of cybersecurity practice across industries. Metrics such as the Common Vulnerability Scoring System (CVSS) and the Exploit Prediction Scoring System (EPSS) provide the numerical foundation for vulnerability prioritisation, network hardening, and policy decisions. Yet, despite their ubiquity, these frameworks face persistent challenges: inconsistencies across databases, disagreements between assessors, and a lack of contextual understanding of system-wide risk. Human-based efforts delay security assessments, leading to larger attack windows.Recent advances in machine learning and generative AI introduce both new possibilities and new uncertainties. Predictive models can learn to forecast exploit likelihoods or automate vulnerability explanations, but when trained on inconsistent data, they risk amplifying human bias rather than resolving it.
    This talk traces the evolution of quantifiable security, from standardised scoring frameworks, to the development of holistic system-level quantification, and finally to AI-driven prediction. I will also discuss current research that uncovers systemic inconsistencies in vulnerability datasets. It will finally outline emerging opportunities to build transparent, explainable, and confidence-aware metrics that bridge the gap between automated risk prediction and trustworthy human decision-making.
     </p>
    <p><strong>About:</strong> Since 2024, Mengyuan is an Assistant Professor at the Vrije Universiteit (VU) Amsterdam in the Foundational and Experimental Security group of the Department of Computer Science. Previously, she worked as a Research Assistant Professor in the Department of Computing at the Hong Kong Polytechnic University and as an Experienced Researcher at Ericsson Research Canada. She received my B.E. and M.E. in Information Security from Nanjing University of Posts and Telecommunications, and hold a Ph.D. in Information and Systems Engineering from Concordia University, Montreal, Canada, under the supervision of Prof. Lingyu Wang.</p>
    <p>Her interests include security metrics, software security, vulnerability assessment, cloud/5G security & privacy, and applied ML in security.</p>
    <p>
      <a href="https://mengyuanzhang.github.io/">Profile</a> ·
      <a href="https://scholar.google.com/citations?user=XebXoxIAAAAJ">Google Scholar</a>
    </p>
  </div>
</div>

<hr>

<div class="speaker">
  <img src="{{ '/assets/img/tailia.jpg' | relative_url }}" alt="Dr. Tailia Malloy headshot" loading="lazy">
  <div class="speaker-body">
    <h3>Dr. Tailia Malloy <span>— University of Luxembourg</span></h3>
    <p><strong>Talk Title:</strong> <em>Human-AI Interdependence in Security and Privacy</em></p>
    <p><strong>Abstract:</strong> Large Language Models (LLMs) and other forms of Generative Artificial Intelligence (GAI) have become ubiquitous in real world applications. This has raised considerable concern over the potential harm that these systems may have in a wide variety of domains. To prevent negative security and privacy outcomes stemming from the use of these models, it is necessary to understand their threats and benefits. These threats are introduced by malicious applications by bad actors, such as social engineering or cyber-attacks, as well as unintentional use by benign actors such as insecure code generation or incorrect information dissemination. Potential benefits of these models include use by cybersecurity professionals to improve the effectiveness of their defense strategies and use by the public to help inform them of best practices to ensure their privacy and security. This is further complicated by the recent advancements in agentic AI, which adds additional complexity to our interaction with AI. In this talk I will detail a human centric perspective on understanding these various challenges and opportunities, drawing from human-computer interaction, cognitive science, and artificial intelligence research to highlight the importance of understanding how humans form interdependent relationships with AI models, and how this impacts security and privacy.</p>
    <p><strong>About:</strong> Tailia Malloy (They/She) is a postdoc at the University of Luxembourg in the Interdisciplinary Center for Security, Reliability, and Trust, researching Large Language Model applications in personalization, cybersecurity, and human interaction. Before starting at UniLu, they had another position as a postdoc at Carnegie Mellon University in the Social and Decision Sciences department working in cognitive modeling with Generative AI models and Human-AI Interaction. They received their PhD from Rensselaer Polytech Institute in Cognitive Science, with their thesis focusing on Deep Reinforcement Learning and cognitive modeling. </p>
  </div>
</div>

<style>
.speaker{
  display:flex; gap:1rem; align-items:flex-start;
  background:#fff; border:1px solid #eee; border-radius:12px;
  padding:16px; box-shadow:0 1px 3px rgba(0,0,0,.04); margin:1rem 0;
}
.speaker img{
  width:110px; height:110px; border-radius:50%;
  object-fit:cover; border:1px solid #eee; flex:0 0 110px;
}
.speaker-body{min-width:0}
.speaker-body h3{margin:.2rem 0}
.speaker-body h3 span{font-weight:400; color:#666}
.speaker-body p{margin:.35rem 0}
@media (max-width: 540px){
  .speaker{flex-direction:column; align-items:center; text-align:center}
  .speaker img{width:96px; height:96px}
}
</style>
 

## Programme
The workshop will be held in Commissiekamer 3 - 20 Aula Conference Centre - TU Delft.

| **Time**    | **What**                |
|-------------|-------------------------|
| 9:30-10:00  | Walk-in                 |
| 10:00-10:10 | Welcome                 |
| 10:10-11:00 | Keynote                 |
| 11:00-11:15 | Coffee                  |
| 11:15-12:15 | Poster/Breakout session |
| 12:15-13:15 | Lunch                   |
| 13:15-14:15 | Keynote                 |
| 14:150-14:30 | Coffee                  |
| 14:30-16:00 | Breakout sessions       |
| 16:00-    | Drinks & Bitterballen   |

## Organizers

<div style="display:grid;grid-template-columns:repeat(auto-fit,minmax(220px,1fr));gap:16px;align-items:start;max-width:1000px;margin:0 auto 1rem;">
  <figure style="text-align:center;margin:0;">
    <img src="{{ '/assets/img/katja-tuma.jpeg' | relative_url }}" alt="Katja Tuma" style="width:160px;height:160px;object-fit:cover;border-radius:50%;display:block;margin:0 auto 8px;">
    <figcaption><strong>Katja Tuma</strong><br><span style="opacity:.8">TU Eindhoven</span><br><a href="mailto:k.tuma@tue.nl">k.tuma@tue.nl</a></figcaption>
  </figure>
  <figure style="text-align:center;margin:0;">
    <img src="{{ '/assets/img/megha-khosla.jpg' | relative_url }}" alt="Megha Khosla" style="width:160px;height:160px;object-fit:cover;border-radius:50%;display:block;margin:0 auto 8px;">
    <figcaption><strong>Megha Khosla</strong><br><span style="opacity:.8">TU Delft</span><br><a href="mailto:m.khosla@tudelft.nl">m.khosla@tudelft.nl</a></figcaption>
  </figure>
  <figure style="text-align:center;margin:0;">
    <img src="{{ '/assets/img/thijs-van-ede.jpg' | relative_url }}" alt="Thijs van Ede" style="width:160px;height:160px;object-fit:cover;border-radius:50%;display:block;margin:0 auto 8px;">
    <figcaption><strong>Thijs van Ede</strong><br><span style="opacity:.8">University of Twente</span><br><a href="mailto:t.s.vanede@utwente.nl">t.s.vanede@utwente.nl</a></figcaption>
  </figure>
</div>